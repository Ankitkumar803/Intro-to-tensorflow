{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN on MNSIT_dataset",
      "provenance": [],
      "authorship_tag": "ABX9TyNOXMZGwUcGg47OPiV7SmAh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Callbacks in TensorFlow using the MNIST Dataset"
      ],
      "metadata": {
        "id": "jSVkjfxJEoCJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BlzJHeC3EalO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "# Normalize pixel values\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255"
      ],
      "metadata": {
        "id": "MCJOTAXXHLAy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_shape = x_train.shape\n",
        "\n",
        "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxZ_zT5_E1JY",
        "outputId": "b59ae5c6-240f-441a-bb13-34108c75f5b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 60000 examples with shape (28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED CLASS: myCallback\n",
        "### START CODE HERE\n",
        "\n",
        "# Remember to inherit from the correct class\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "        # Define the correct function signature for on_epoch_end\n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:\n",
        "                print(\"\\nReached 99% accuracy so cancelling training!\") \n",
        "                \n",
        "                # Stop training once the above condition is met\n",
        "                self.model.stop_training = True\n",
        "\n",
        "### END CODE HERE"
      ],
      "metadata": {
        "id": "sB4yjqEEE4Z-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: train_mnist\n",
        "def train_mnist(x_train, y_train,x_test,y_test):\n",
        "\n",
        "    ### START CODE HERE\n",
        "    \n",
        "    # Instantiate the callback class\n",
        "    callbacks = myCallback()\n",
        "    \n",
        "    # Define the model, it should have 3 layers:\n",
        "    # - A Flatten layer that receives inputs with the same shape as the images\n",
        "    # - A Dense layer with 512 units and ReLU activation function\n",
        "    # - A Dense layer with 10 units and softmax activation function\n",
        "    model = tf.keras.models.Sequential([ \n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ]) \n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', \n",
        "                  loss='sparse_categorical_crossentropy', \n",
        "                  metrics=['accuracy']) \n",
        "    \n",
        "    # Fit the model for 10 epochs adding the callbacks\n",
        "    # and save the training history\n",
        "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
        "\n",
        "    ### Extra code added by me \n",
        "    import numpy as np\n",
        "    classifications = model.predict(x_test)\n",
        "    prediction1 = np.argmax(classifications, axis = 1)\n",
        "\n",
        "    from sklearn.metrics import accuracy_score\n",
        "   \n",
        "    print('Test Data accuracy: ',accuracy_score(y_test, prediction1)*100)\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "4dxO2otIE47t"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hist = train_mnist(x_train, y_train)\n",
        "#Modified one\n",
        "hist = train_mnist(x_train, y_train,x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj00GbqME5ZE",
        "outputId": "8c09a0bb-850e-4f28-a404-177f5e6c1e3b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2032 - accuracy: 0.9407\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0823 - accuracy: 0.9756\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0523 - accuracy: 0.9839\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0378 - accuracy: 0.9884\n",
            "Epoch 5/10\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9908\n",
            "Reached 99% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0283 - accuracy: 0.9908\n",
            "Test Data accuracy:  97.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### START CODE HERE\n",
        "\n",
        "# Instantiate the callback class\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Define the model, it should have 3 layers:\n",
        "# - A Flatten layer that receives inputs with the same shape as the images\n",
        "# - A Dense layer with 512 units and ReLU activation function\n",
        "# - A Dense layer with 10 units and softmax activation function\n",
        "model = tf.keras.models.Sequential([ \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "]) \n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy']) \n",
        "\n",
        "# Fit the model for 10 epochs adding the callbacks\n",
        "# and save the training history\n",
        "history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
        "\n",
        "### Extra code added by me \n",
        "import numpy as np\n",
        "classifications = model.predict(x_test)\n",
        "prediction1 = np.argmax(classifications, axis = 1)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Test Data accuracy: ',accuracy_score(y_test, prediction1)*100)\n",
        "\n",
        "### END CODE HERE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrfSh3ynZGET",
        "outputId": "ff16d83d-217a-479a-a4ea-f14340918ef2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1993 - accuracy: 0.9415\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0805 - accuracy: 0.9761\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0521 - accuracy: 0.9838\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0369 - accuracy: 0.9883\n",
            "Epoch 5/10\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9914\n",
            "Reached 99% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0273 - accuracy: 0.9914\n",
            "Test Data accuracy:  97.85000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the weights\n",
        "model.save_weights('./my_checkpoint')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sbqr_pn4ZdpJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple sequential model\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([ \n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ]) \n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', \n",
        "                  loss='sparse_categorical_crossentropy', \n",
        "                  metrics=['accuracy']) \n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "EtGI30V8blGC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new model instance\n",
        "model1 = create_model()\n",
        "\n",
        "# Restore the weights\n",
        "model1.load_weights('./my_checkpoint')\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFivfG3dbQTY",
        "outputId": "8dcab89c-9046-4881-a647-5512053ce613"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.0750 - accuracy: 0.9785 - 778ms/epoch - 2ms/step\n",
            "Restored model, accuracy: 97.85%\n"
          ]
        }
      ]
    }
  ]
}